{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_classifier.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1puZtSKm1pKAhJX_5CZofxQ1uHRoN9FXO",
      "authorship_tag": "ABX9TyM1FM0WlmdEeUAgFaJxSvrO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newbeechallenger/dragon1/blob/main/training_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08_vLZ7BlAib"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GFmLCUielmeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/dataset/Kuroko_X_Kagami.zip -d /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "TzOwpEOTl4b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Model\n",
        "from torch import nn\n",
        "\n",
        "class SuperLightMobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(SuperLightMobileNet, self).__init__()\n",
        "\n",
        "        def conv_bn(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        def conv_dw(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
        "                nn.BatchNorm2d(inp),\n",
        "                nn.ReLU(inplace=True),\n",
        "    \n",
        "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.num_classes = num_classes\n",
        "        self.model = nn.Sequential(\n",
        "            conv_bn(  3,  16, 2), \n",
        "            conv_dw( 16,  32, 1),\n",
        "            conv_dw( 32, 64, 2),\n",
        "            conv_dw(64, 64, 1),\n",
        "            conv_dw(64, 128, 2),\n",
        "            conv_dw(128, 128, 1),\n",
        "            conv_dw(128, 256, 2),\n",
        "            conv_dw(256, 256, 1),\n",
        "            conv_dw(256, 512, 2),\n",
        "            conv_dw(512, 512, 1),\n",
        "            conv_dw(512, 1024, 1)\n",
        "        )\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "b2o3DaU2mNIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Hyperprameters & Device Setting\n",
        "import torch\n",
        "\n",
        "#hyp parameters\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/Kuroko_X_Kagami\"\n",
        "model_weight_save_path = \"/content/drive/MyDrive/Model/\"\n",
        "num_classes = 2\n",
        "\n",
        "batch_size = 16\n",
        "num_workers = 8\n",
        "lr = 1e-3\n",
        "\n",
        "total_epoch = 30\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Cjn_ggYrmpO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset & Dataloader Setting\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "\n",
        "# Data loading code\n",
        "traindir = os.path.join(dataset_path, 'train')\n",
        "testdir = os.path.join(dataset_path, 'test')\n",
        "\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                   std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    traindir,\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #normalize,\n",
        "    ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True,\n",
        "    num_workers=num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(testdir, transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        #normalize,\n",
        "    ])),\n",
        "    batch_size=batch_size, shuffle=False,\n",
        "    num_workers=num_workers, pin_memory=True)"
      ],
      "metadata": {
        "id": "OkQkmEJmm3iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Model Initialization\n",
        "\n",
        "model = SuperLightMobileNet(num_classes).to(device)"
      ],
      "metadata": {
        "id": "92MAh8ewnC5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Loss & Optimizer\n",
        "CEloss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "SJnQ0g7snGiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training & Evaluation\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "total_iteration_per_epoch = int(np.ceil(len(train_dataset)/batch_size))\n",
        "\n",
        "for epoch in range(1, total_epoch + 1):\n",
        "    model.train()\n",
        "    for itereation, (input, target) in enumerate(train_loader):\n",
        "        images = input.to(device)\n",
        "        labels = target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = CEloss(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch [{}/{}], Iteration [{}/{}] Loss: {:.4f}'.format(epoch, total_epoch, itereation+1, total_iteration_per_epoch, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "      torch.save(model.state_dict(), model_weight_save_path + 'model_' + str(epoch) + \".pth\")\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for input, target in test_loader:\n",
        "          images = input.to(device)\n",
        "          labels = target.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += len(labels)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Epoch [{}/{}], Test Accuracy of the model on the {} test images: {} %'.format(epoch, total_epoch, total, 100 * correct / total))"
      ],
      "metadata": {
        "id": "_RH8nqxsnLZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}